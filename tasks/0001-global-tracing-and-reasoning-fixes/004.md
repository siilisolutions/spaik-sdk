# 004: Fix OpenAI reasoning disable

## Context

The OpenAI factory has two issues with reasoning configuration:

1. **Wrong field checked**: The factory checks `config.model.reasoning` (whether the model supports reasoning) instead of `config.reasoning` (whether the user wants reasoning). This means if you use a reasoning-capable model but set `reasoning=False`, the factory ignores your preference.

2. **No disable mechanism**: Even if the correct field were checked, the factory doesn't have logic to disable reasoning. For OpenAI models, disabling reasoning requires setting the reasoning effort level appropriately:
   - GPT-5.1 and later (including codex variants, 5.2): supports `reasoning.effort = "none"` to fully disable
   - GPT-5 base models (5, 5-mini, 5-nano): minimum is `reasoning.effort = "minimal"` (full disable not supported by API)

## Related Code

Existing files/patterns to reference or extend:
- `spaik_sdk/models/factories/openai_factory.py` - The file to modify, contains get_model_specific_config method
- `spaik_sdk/models/factories/anthropic_factory.py` - Shows correct pattern of checking config.reasoning (user preference)
- `spaik_sdk/models/model_registry.py` - Contains model definitions, useful for understanding model naming conventions
- `spaik_sdk/models/llm_config.py` - Contains LLMConfig with reasoning field

## Reuse Opportunities

- Model version detection can use simple string matching on config.model.name (models are named consistently: "gpt-5", "gpt-5-mini", "gpt-5.1", "gpt-5.1-codex", etc.)
- The existing conditional structure in openai_factory.py can be extended with additional branches
- Anthropic factory shows the pattern of explicitly handling both reasoning=True and reasoning=False

## Deliverables

- Update OpenAIModelFactory.get_model_specific_config to check config.reasoning (user preference) instead of config.model.reasoning (capability)
- Add logic to detect model version from model name to determine which effort level to use
- When reasoning is disabled on GPT-5.1+ models, set reasoning effort to "none"
- When reasoning is disabled on GPT-5 base models, set reasoning effort to "minimal"
- Maintain existing behavior when reasoning is enabled

## Acceptance Criteria

- [x] Factory checks config.reasoning (user preference), not config.model.reasoning (capability)
- [x] When reasoning=False on GPT-5.1 model, reasoning effort is "none"
- [x] When reasoning=False on GPT-5.1-codex model, reasoning effort is "none"
- [x] When reasoning=False on GPT-5.1-codex-mini model, reasoning effort is "none"
- [x] When reasoning=False on GPT-5.1-codex-max model, reasoning effort is "none"
- [x] When reasoning=False on GPT-5.2 model, reasoning effort is "none"
- [x] When reasoning=False on GPT-5.2-pro model, reasoning effort is "none"
- [x] When reasoning=False on GPT-5 model, reasoning effort is "minimal"
- [x] When reasoning=False on GPT-5-mini model, reasoning effort is "minimal"
- [x] When reasoning=False on GPT-5-nano model, reasoning effort is "minimal"
- [x] When reasoning=True, existing behavior is preserved (Responses API enabled, configurable effort)
- [x] Unit tests verify model config output for each model variant with reasoning=False
